import json
import logging
import os
import asyncio
import time
from typing import Dict, List, Any, TypedDict, Annotated
from enum import Enum

from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage, AIMessage
from langchain_core.tools import tool
from langchain_openai import AzureChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from shared.gemini_agent import GeminiAgent

from langchain_mcp_adapters.client import MultiServerMCPClient

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

class LLMProvider(Enum):
    AZURE_OPENAI = "azure_openai"
    GEMINI = "gemini"


class AgentState(TypedDict):
    messages: Annotated[List[Any], add_messages]
    device_ids: Dict[str, str]
    llm_provider: str


class SmartSpeakerAgent:
    def __init__(self, llm_provider: str = "azure_openai"):
        init_start = time.time()
        logger.info(f"ğŸš€ SmartSpeakerAgent initialization started")
        
        self.llm_provider = llm_provider
        self.mcp_client = None
        
        # LLMä½œæˆæ™‚é–“è¨ˆæ¸¬
        llm_start = time.time()
        self.llm = self._create_llm()
        llm_time = time.time() - llm_start
        logger.info(f"â±ï¸ LLM creation: {llm_time:.3f}s")
        
        # GeminiAgentä½œæˆæ™‚é–“è¨ˆæ¸¬
        gemini_start = time.time()
        self.gemini_search_agent = GeminiAgent()
        gemini_time = time.time() - gemini_start
        logger.info(f"â±ï¸ GeminiAgent creation: {gemini_time:.3f}s")
        
        # éåŒæœŸåˆæœŸåŒ–ã‚’åŒæœŸçš„ã«å®Ÿè¡Œ
        logger.info(f"ğŸ”„ Starting async initialization during __init__")
        self.tools = asyncio.run(self._create_tools())
        self.device_ids = asyncio.run(self.get_actual_device_ids())
        self.graph = self._create_graph()
        self._initialized = True
        
        init_total = time.time() - init_start
        logger.info(f"âœ… SmartSpeakerAgent initialization completed: {init_total:.3f}s")
        
        # ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._device_cache = None
        self._device_cache_timestamp = None
        self._cache_ttl = 300  # 5åˆ†é–“æœ‰åŠ¹
    
    async def _ensure_initialized(self):
        """å¿…è¦ã«å¿œã˜ã¦éåŒæœŸåˆæœŸåŒ–ã‚’å®Ÿè¡Œ"""
        if not self._initialized:
            async_init_start = time.time()
            logger.info(f"ğŸ”„ Async initialization started")
            
            # ãƒ„ãƒ¼ãƒ«ä½œæˆæ™‚é–“è¨ˆæ¸¬
            tools_start = time.time()
            self.tools = await self._create_tools()
            tools_time = time.time() - tools_start
            logger.info(f"â±ï¸ Tools creation: {tools_time:.3f}s")
            
            # ãƒ‡ãƒã‚¤ã‚¹IDå–å¾—æ™‚é–“è¨ˆæ¸¬
            devices_start = time.time()
            self.device_ids = self._get_default_devices()  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‡ãƒã‚¤ã‚¹ã‚’ä½¿ç”¨
            devices_time = time.time() - devices_start
            logger.info(f"â±ï¸ Device IDs setup: {devices_time:.3f}s")
            
            # ã‚°ãƒ©ãƒ•ä½œæˆæ™‚é–“è¨ˆæ¸¬
            graph_start = time.time()
            self.graph = self._create_graph()
            graph_time = time.time() - graph_start
            logger.info(f"â±ï¸ Graph creation: {graph_time:.3f}s")
            
            self._initialized = True
            
            async_init_total = time.time() - async_init_start
            logger.info(f"âœ… Async initialization completed: {async_init_total:.3f}s")
    
    async def _initialize_mcp_client(self):
        """MCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ï¼ˆè¨˜äº‹ã«å¾“ã£ãŸå®Ÿè£…ï¼‰"""
        if self.mcp_client:
            return self.mcp_client
            
        try:
            mcp_start = time.time()
            logger.info(f"ğŸ”Œ MCP client initialization started")
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼æƒ…å ±ã¯ç¾åœ¨ä½¿ç”¨ã—ãªã„
            
            # SwitchBot MCP ã‚µãƒ¼ãƒãƒ¼ã®è¨­å®šï¼ˆ.mcp.jsonã‹ã‚‰å–å¾—ï¼‰
            mcp_extension_key = os.getenv("MCP_EXTENSION_KEY")
            
            client = MultiServerMCPClient({
                "switchbot": {
                    "transport": "sse",
                    "url": "https://oai-alexa.azurewebsites.net/runtime/webhooks/mcp/sse",
                    "headers": {
                        "x-functions-key": mcp_extension_key
                    }
                }
            })
            
            mcp_time = time.time() - mcp_start
            logger.info(f"âœ… SwitchBot MCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†: {mcp_time:.3f}s")
            return client
            
        except Exception as e:
            mcp_time = time.time() - mcp_start if 'mcp_start' in locals() else 0
            logger.error(f"âŒ MCP client initialization failed after {mcp_time:.3f}s: {e}")
            return None
    
    def _is_cache_valid(self) -> bool:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæœ‰åŠ¹ã‹ã©ã†ã‹ã‚’ç¢ºèª"""
        if self._device_cache is None or self._device_cache_timestamp is None:
            return False
        
        current_time = time.time()
        return (current_time - self._device_cache_timestamp) < self._cache_ttl
    
    async def _get_switchbot_devices_via_mcp(self) -> Dict[str, Any]:
        """MCPã‚’ä½¿ç”¨ã—ã¦SwitchBotãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ä»˜ãï¼‰"""
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæœ‰åŠ¹ãªå ´åˆã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰è¿”ã™
        if self._is_cache_valid():
            logger.info("ğŸ“‹ Using cached device information")
            return self._device_cache
        
        try:
            if self.mcp_client:
                # MCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ãƒ„ãƒ¼ãƒ«ã‚’å–å¾—
                tools = await self.mcp_client.get_tools()
                # get_switchbot_devicesãƒ„ãƒ¼ãƒ«ã‚’æ¢ã™
                for tool in tools:
                    if tool.name == "get_switchbot_devices":
                        result = await tool.ainvoke({})
                        
                        # çµæœãŒæ–‡å­—åˆ—ã®å ´åˆã¯JSONã¨ã—ã¦è§£æ
                        parsed_result = json.loads(result)
                        if 'body' in parsed_result:
                            result = parsed_result['body']
                        else:
                            result = parsed_result
                        
                        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
                        if result:
                            self._device_cache = result
                            logger.info(f"ğŸ’¾ Device info cached")

                        return result if result else {}
                logger.warning("SwitchBotãƒ‡ãƒã‚¤ã‚¹å–å¾—ãƒ„ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return {}

        except Exception as e:
            logger.error(f"MCPã§ã®ãƒ‡ãƒã‚¤ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    
    async def get_actual_device_ids(self) -> Dict[str, str]:
        """å®Ÿéš›ã®ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ã‚’å–å¾—ï¼ˆIoTæ“ä½œæ™‚ã«ä½¿ç”¨ï¼‰"""
            # SwitchBotãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ä»˜ãï¼‰
        devices_info = await self._get_switchbot_devices_via_mcp()
        
        if not devices_info:
            logger.warning("SwitchBotãƒ‡ãƒã‚¤ã‚¹ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

        device_mapping = {}
        
        # iot_agent.pyã®å®Ÿè£…ã«åˆã‚ã›ã¦ãƒ‡ãƒã‚¤ã‚¹ãƒãƒƒãƒ”ãƒ³ã‚°
        # Get light and aircon device IDs from infraredRemoteList
        light_device_id = next((device['deviceId'] for device in devices_info.get('infraredRemoteList', [])
                                if device['remoteType'] == 'Light'), None)
        
        aircon_device_id = next((device['deviceId'] for device in devices_info.get('infraredRemoteList', [])
                                if device['remoteType'] == 'Air Conditioner'), None)
        
        # Find Hub 2 device from deviceList
        hub2_device_id = None
        for device in devices_info.get('deviceList', []):
            if device.get('deviceType') == 'Hub 2':
                hub2_device_id = device['deviceId']
                logger.info(f"SmartSpeaker-Agent: Hub 2ãƒ‡ãƒã‚¤ã‚¹ã‚’æ¤œå‡º: {device.get('deviceName', 'Unknown')} (ID: {hub2_device_id})")
                break
        
        if not hub2_device_id:
            logger.warning("è­¦å‘Š: Hub 2ãƒ‡ãƒã‚¤ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å®¤å†…ç’°å¢ƒæƒ…å ±ã®å–å¾—ãŒã§ãã¾ã›ã‚“ã€‚")
        
        device_mapping = {
            'light_device_id': light_device_id,
            'aircon_device_id': aircon_device_id,
            'hub2_device_id': hub2_device_id
        }
        
        logger.info(f"SwitchBotãƒ‡ãƒã‚¤ã‚¹ãƒãƒƒãƒ”ãƒ³ã‚°: {device_mapping}")
        return device_mapping



    
    def _get_default_devices(self) -> Dict[str, str]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ‡ãƒã‚¤ã‚¹è¨­å®šã‚’è¿”ã™"""
        return {
            'light_device_id': "02-202403301114-45200468",
            'aircon_device_id': "02-202504191706-42866040", 
            'hub2_device_id': "C6FD9F3D1826"
        }
    
    def _create_llm(self):
        """LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã«å¿œã˜ã¦LLMã‚’ä½œæˆ"""
        if self.llm_provider == LLMProvider.AZURE_OPENAI.value:
            return AzureChatOpenAI(
                api_version=os.getenv("AZURE_OPENAI_VERSION"),
                azure_endpoint=os.getenv("AZURE_ENDPOINT"),
                api_key=os.getenv("AZURE_OPENAI_KEY"),
                azure_deployment=os.getenv("DEPLOYMENT_NAME"),
                temperature=0.1,
            )
        elif self.llm_provider == LLMProvider.GEMINI.value:
            return ChatGoogleGenerativeAI(
                model="gemini-2.5-flash-light",
                api_key=os.getenv("GEMINI_API_KEY"),
                temperature=0.1,
            )
        else:
            raise ValueError(f"Unsupported LLM provider: {self.llm_provider}")
    
    async def _create_tools(self):
        """MCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰SwitchBotãƒ„ãƒ¼ãƒ«ã¨Geminiæ¤œç´¢ãƒ„ãƒ¼ãƒ«ã‚’å–å¾—"""
        create_tools_start = time.time()
        logger.info(f"ğŸ”§ Tool creation started")
        tools = []
        
        # MCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–æ™‚é–“è¨ˆæ¸¬
        mcp_init_start = time.time()
        self.mcp_client = await self._initialize_mcp_client()
        mcp_init_time = time.time() - mcp_init_start
        logger.info(f"â±ï¸ MCP client init: {mcp_init_time:.3f}s (result: {self.mcp_client is not None})")
        
        if self.mcp_client:
            try:
                # MCPãƒ„ãƒ¼ãƒ«å–å¾—æ™‚é–“è¨ˆæ¸¬
                mcp_tools_start = time.time()
                mcp_tools = await self.mcp_client.get_tools()
                mcp_tools_time = time.time() - mcp_tools_start
                logger.info(f"â±ï¸ MCP tools fetch: {mcp_tools_time:.3f}s ({len(mcp_tools)} tools)")
                tools.extend(mcp_tools)
            except Exception as e:
                mcp_tools_time = time.time() - mcp_tools_start if 'mcp_tools_start' in locals() else 0
                logger.error(f"âŒ MCP tools fetch failed after {mcp_tools_time:.3f}s: {e}")
        else:
            logger.warning("MCPãƒ„ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        
        # Geminiæ¤œç´¢ãƒ„ãƒ¼ãƒ«ä½œæˆæ™‚é–“è¨ˆæ¸¬
        gemini_tool_start = time.time()
        @tool
        def gemini_search(query: str) -> Dict[str, Any]:
            """Geminiã®æ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¦Webæ¤œç´¢ã‚’å®Ÿè¡Œã—ã¾ã™
            
            Args:
                query: èƒŒæ™¯ã¨æ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆè³ªå•ã‚„èª¿ã¹ãŸã„ã“ã¨ï¼‰èƒŒæ™¯ã‚’å«ã‚ã‚‹ã¨æ¤œç´¢ç²¾åº¦ã‚‚å‘ä¸Š
            
            Returns:
                æ¤œç´¢çµæœã‚’å«ã‚€è¾æ›¸
            """
            try:
                result = self.gemini_search_agent.chat(query)
                
                return {
                    "response": result.response,
                    "citations": result.citations,
                    "grounding_metadata": result.grounding_metadata,
                    "success": True
                }
            except Exception as e:
                logger.error(f"Geminiæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
                return {
                    "response": f"æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
                    "citations": [],
                    "grounding_metadata": None,
                    "success": False
                }
        
        tools.append(gemini_search)
        gemini_tool_time = time.time() - gemini_tool_start
        logger.info(f"â±ï¸ Gemini tool creation: {gemini_tool_time:.3f}s")
        
        # å…¨ä½“ã®æ™‚é–“è¨ˆæ¸¬
        create_tools_total = time.time() - create_tools_start
        logger.info(f"âœ… Tool creation completed: {len(tools)} tools in {create_tools_total:.3f}s")
        logger.info(f"ğŸ“Š Breakdown - MCP init: {mcp_init_time:.3f}s | MCP fetch: {mcp_tools_time:.3f}s | Gemini: {gemini_tool_time:.3f}s")
        return tools
    
    def _create_graph(self):
        """LangGraphã®ã‚°ãƒ©ãƒ•ã‚’ä½œæˆï¼ˆMCPãƒ„ãƒ¼ãƒ«ã®ã¿ä½¿ç”¨ï¼‰"""
        async def agent_node(state: AgentState):
            """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ‰ - LLMãŒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†"""
            messages = state["messages"]
            
            llm_with_tools = self.llm.bind_tools(self.tools)
            response = await llm_with_tools.ainvoke(messages)
            
            return {"messages": [response]}
        
        async def tools_node(state: AgentState):
            """çµ±åˆãƒ„ãƒ¼ãƒ«ãƒãƒ¼ãƒ‰ - å…¨ã¦ã®ãƒ„ãƒ¼ãƒ«ï¼ˆMCP + Geminiï¼‰ã‚’å‡¦ç†"""
            messages = state["messages"]
            last_message = messages[-1]
            
            if not (hasattr(last_message, 'tool_calls') and last_message.tool_calls):
                return state
            
            try:
                # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œæ™‚é–“ã‚’è¨ˆæ¸¬
                tool_start = time.time()
                tool_calls = last_message.tool_calls
                logger.info(f"ğŸ”§ Tool calls: {[call['name'] for call in tool_calls]}")
                
                # çµ±ä¸€åŒ–ã•ã‚ŒãŸãƒ„ãƒ¼ãƒ«ã‚»ãƒƒãƒˆï¼ˆself.toolsï¼‰ã‚’ä½¿ç”¨
                tool_node = ToolNode(self.tools)
                result = await tool_node.ainvoke(state)
                
                tool_time = time.time() - tool_start
                logger.info(f"â±ï¸ Tool execution time: {tool_time:.2f}s")
                return result
                    
            except Exception as e:
                tool_time = time.time() - tool_start if 'tool_start' in locals() else 0
                logger.error(f"Tools node error after {tool_time:.2f}s: {e}")
                return state
        
        def should_continue(state: AgentState):
            """ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒå¿…è¦ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
            messages = state["messages"]
            last_message = messages[-1]
            
            if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
                return "tools"
            return END
        
        # ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰
        workflow = StateGraph(AgentState)
        
        # ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ 
        workflow.add_node("agent", agent_node)
        workflow.add_node("tools", tools_node)
        
        # ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ 
        workflow.add_edge(START, "agent")
        workflow.add_conditional_edges("agent", should_continue, ["tools", END])
        workflow.add_edge("tools", "agent")
        
        return workflow.compile()
    
    def get_system_message(self) -> str:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™"""
        return """
ã‚ãªãŸã¯ã‚¹ãƒãƒ¼ãƒˆã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®éŸ³å£°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š
1. ç…§æ˜ã®ç‚¹ç¯ãƒ»æ¶ˆç¯åˆ¶å¾¡
2. ã‚¨ã‚¢ã‚³ãƒ³ã®æ¸©åº¦ãƒ»ãƒ¢ãƒ¼ãƒ‰ãƒ»é¢¨é‡åˆ¶å¾¡
3. å®¤å†…ç’°å¢ƒæƒ…å ±ã®ç¢ºèªï¼ˆæ¸©åº¦ã€æ¹¿åº¦ã€ç…§åº¦ï¼‰
4. Webæ¤œç´¢ã«ã‚ˆã‚‹æœ€æ–°æƒ…å ±ã®æä¾›

éŸ³å£°ã§ã®å¯¾è©±ã‚’å‰æã¨ã—ãŸå¿œç­”ã‚’ã—ã¦ãã ã•ã„ï¼š
- ç°¡æ½”ã§èãå–ã‚Šã‚„ã™ã„å›ç­”
- å°‚é–€ç”¨èªã¯é¿ã‘ã€åˆ†ã‹ã‚Šã‚„ã™ã„è¡¨ç¾ã‚’ä½¿ç”¨
- å›ç­”ã¯2-3æ–‡ç¨‹åº¦ã«åã‚ã‚‹
- æ•°å­—ã‚„æ™‚é–“ã¯æ˜ç¢ºã«èª­ã¿ä¸Šã’ã‚‹
ä¾‹ï¼š
- ã€Œé›»æ°—ã‚’ã¤ã‘ã¦ã€â†’ç…§æ˜ã‚’ç‚¹ç¯
- ã€Œæš‘ã„/å¯’ã„ã€â†’é©åˆ‡ãªæ¸©åº¦è¨­å®šã§ã‚¨ã‚¢ã‚³ãƒ³ã‚’æ“ä½œ
- ã€Œä»Šã®éƒ¨å±‹ã®æ¸©åº¦ã¯ï¼Ÿã€â†’ç’°å¢ƒæƒ…å ±ã‚’å–å¾—
- ã€Œã€œã«ã¤ã„ã¦æ•™ãˆã¦ã€â†’Webæ¤œç´¢ã§æœ€æ–°æƒ…å ±ã‚’æä¾›ã€‚è‡ªèº«ã®æƒ…å ±ã«ãªã„å ´åˆã¯å¿…ãšæ¤œç´¢ã™ã‚‹ã“ã¨

ã™ã¹ã¦ã®å¿œç­”ã¯éŸ³å£°ã§ã®èª­ã¿ä¸Šã’ã«é©ã—ãŸè‡ªç„¶ãªæ—¥æœ¬èªã§è¡Œã£ã¦ãã ã•ã„ã€‚
"""
    
    async def chat(self, user_input: str, session_id: str, conversation_history: Dict[str, List] = None) -> str:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’å‡¦ç†ã—ã¦å¿œç­”ã‚’è¿”ã™"""
        start_time = time.time()
        
        try:
            if conversation_history is None:
                conversation_history = {}
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—ã¾ãŸã¯åˆæœŸåŒ–
            if session_id not in conversation_history:
                conversation_history[session_id] = [SystemMessage(content=self.get_system_message())]
            
            messages = conversation_history[session_id].copy()
            messages.append(HumanMessage(content=user_input))
            
            # åˆæœŸçŠ¶æ…‹ã‚’è¨­å®š
            state = AgentState(
                messages=messages,
                device_ids=self.device_ids,
                llm_provider=self.llm_provider
            )
            
            # ã‚°ãƒ©ãƒ•ã‚’éåŒæœŸå®Ÿè¡Œ
            graph_start = time.time()
            result = await self.graph.ainvoke(state)
            graph_time = time.time() - graph_start
            
            # ä¼šè©±å±¥æ­´ã‚’æ›´æ–°
            conversation_history[session_id] = result["messages"]
            
            # æœ€å¾Œã®AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
            last_message = result["messages"][-1]
            if isinstance(last_message, AIMessage):
                response_content = last_message.content
                
                # å®Ÿè¡Œæ™‚é–“ã®ãƒ­ã‚°å‡ºåŠ›
                total_time = time.time() - start_time
                logger.info(f"â±ï¸ Performance Metrics - Total: {total_time:.2f}s | Graph: {graph_time:.2f}s")
                logger.info(f"SmartSpeaker-Response: {response_content}")
                return response_content
            else:
                total_time = time.time() - start_time
                logger.warning(f"â±ï¸ Performance Metrics - Total: {total_time:.2f}s (Failed)")
                return "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚å¿œç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
                
        except Exception as e:
            total_time = time.time() - start_time
            error_message = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            logger.error(f"â±ï¸ Performance Metrics - Total: {total_time:.2f}s (Error)")
            logger.error(error_message)
            return "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"


def create_smart_speaker_agent(llm_provider: str = "azure_openai") -> SmartSpeakerAgent:
    """ã‚¹ãƒãƒ¼ãƒˆã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆã™ã‚‹å·¥å ´é–¢æ•°"""
    return SmartSpeakerAgent(llm_provider)


# ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆ
async def main():
    """éåŒæœŸãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    try:
        agent = SmartSpeakerAgent("azure_openai")
        
        # ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
        queries = [
            "ã‚¨ã‚¢ã‚³ãƒ³æ¶ˆã—ã¦",
            "ä»Šæ—¥ã®å¤©æ°—ã¯ï¼Ÿ"
        ]
        
        session_id = "test_session"
        
        for query in queries:
            print(f"\n=== è³ªå•: {query} ===")
            response = await agent.chat(query, session_id)
            print(f"å›ç­”: {response}")
            
    except Exception as e:
        print(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}")
        print("ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")

if __name__ == "__main__":
    asyncio.run(main())