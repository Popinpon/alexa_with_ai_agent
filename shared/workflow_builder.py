"""
LangGraph ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ§‹ç¯‰ã‚¯ãƒ©ã‚¹
"""
import time
import asyncio
import logging
from typing import List, Dict, Any
from langchain_core.messages import AIMessage, SystemMessage, HumanMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, START, END
from langgraph.prebuilt import ToolNode

from shared.types import AgentState, ConversationState
from shared.conversation_manager import ConversationManager
from shared.gemini_agent import GeminiAgent

logger = logging.getLogger(__name__)


class WorkflowBuilder:
    """LangGraph ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æ§‹ç¯‰ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, llm, tools: List, gemini_agent: GeminiAgent):
        self.llm = llm
        self.tools = tools
        self.gemini_agent = gemini_agent
        self.conversation_manager = ConversationManager(llm)
    
    def create_gemini_tool(self):
        """Geminiæ¤œç´¢ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆ"""
        @tool
        def gemini_search(query: str) -> Dict[str, Any]:
            """Geminiã®æ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¦Webæ¤œç´¢ã‚’å®Ÿè¡Œã—ã¾ã™
            
            Args:
                query: èƒŒæ™¯ã¨æ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆè³ªå•ã‚„èª¿ã¹ãŸã„ã“ã¨ï¼‰èƒŒæ™¯ã‚’å«ã‚ã‚‹ã¨æ¤œç´¢ç²¾åº¦ã‚‚å‘ä¸Š
            
            Returns:
                æ¤œç´¢çµæœã‚’å«ã‚€è¾æ›¸
            """
            try:
                result = self.gemini_agent.chat(query)
                
                return {
                    "response": result.response,
                    "citations": result.citations,
                    "grounding_metadata": result.grounding_metadata,
                    "success": True
                }
            except Exception as e:
                logger.error(f"Geminiæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
                return {
                    "response": f"æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
                    "citations": [],
                    "grounding_metadata": None,
                    "success": False
                }
        
        return gemini_search
    
    def create_agent_graph(self):
        """é€šå¸¸ã®chatç”¨ã®ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ"""
        
        async def agent_node(state: AgentState):
            """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ‰ - LLMãŒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†"""
            messages = state["messages"]
            
            llm_with_tools = self.llm.bind_tools(self.tools)
            response = await llm_with_tools.ainvoke(messages)
            
            return {"messages": [response]}
        
        async def tools_node(state: AgentState):
            """çµ±åˆãƒ„ãƒ¼ãƒ«ãƒãƒ¼ãƒ‰ - å…¨ã¦ã®ãƒ„ãƒ¼ãƒ«ï¼ˆMCP + Geminiï¼‰ã‚’å‡¦ç†"""
            messages = state["messages"]
            last_message = messages[-1]
            
            if not (hasattr(last_message, 'tool_calls') and last_message.tool_calls):
                return state
            
            try:
                # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œæ™‚é–“ã‚’è¨ˆæ¸¬
                tool_start = time.time()
                tool_calls = last_message.tool_calls
                logger.info(f"ğŸ”§ Tool calls: {[call['name'] for call in tool_calls]}")
                
                # çµ±ä¸€åŒ–ã•ã‚ŒãŸãƒ„ãƒ¼ãƒ«ã‚»ãƒƒãƒˆï¼ˆself.toolsï¼‰ã‚’ä½¿ç”¨
                tool_node = ToolNode(self.tools)
                result = await tool_node.ainvoke(state)
                
                tool_time = time.time() - tool_start
                logger.info(f"â±ï¸ Tool execution time: {tool_time:.2f}s")
                return result
                    
            except Exception as e:
                tool_time = time.time() - tool_start if 'tool_start' in locals() else 0
                logger.error(f"Tools node error after {tool_time:.2f}s: {e}")
                return state
        
        def should_continue(state: AgentState):
            """ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒå¿…è¦ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
            messages = state["messages"]
            last_message = messages[-1]
            
            if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
                return "tools"
            return END
        
        # AgentStateç”¨ã®ã‚°ãƒ©ãƒ•ï¼ˆé€šå¸¸ã®chatï¼‰
        agent_workflow = StateGraph(AgentState)
        agent_workflow.add_node("agent", agent_node)
        agent_workflow.add_node("tools", tools_node)
        agent_workflow.add_edge(START, "agent")
        agent_workflow.add_conditional_edges("agent", should_continue, ["tools", END])
        agent_workflow.add_edge("tools", "agent")
        
        return agent_workflow.compile()
    
    def create_conversation_graph(self):
        """ä¼šè©±ã‚µã‚¤ã‚¯ãƒ«ç”¨ã®ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ"""
        
        async def input_analysis_node(state: ConversationState):
            """å…¥åŠ›åˆ†æãƒãƒ¼ãƒ‰"""
            last_message = state["messages"][-1].content
            session_id = state["session_id"]
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«æœªå®Œäº†ã‚¿ã‚¹ã‚¯ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            has_pending = self.conversation_manager.has_pending_session(session_id)
            
            if not has_pending:
                input_type = "new_question"
                processing_start = time.time()
            else:
                # LLMã§ç¶™ç¶šæ„å›³ã‚’åˆ¤å®š
                input_type = await self.conversation_manager.analyze_continuation_intent(last_message)
                processing_start = state.get("processing_start_time", time.time())
            
            return {
                "user_input_type": input_type,
                "processing_start_time": processing_start,
                "is_processing": True,
                "has_timeout": False
            }
        
        async def agent_processing_node(state: ConversationState):
            """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†ãƒãƒ¼ãƒ‰ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç›£è¦–ä»˜ãï¼‰"""
            input_type = state["user_input_type"]
            
            if input_type == "continuation_yes":
                return await self._resume_processing(state)
            else:
                return await self._process_with_timeout_monitoring(state)
        
        async def response_preparation_node(state: ConversationState):
            """å¿œç­”æº–å‚™ãƒãƒ¼ãƒ‰"""
            if state["has_timeout"]:
                return self.conversation_manager.prepare_timeout_response(state)
            else:
                return self.conversation_manager.prepare_completion_response(state)
        
        async def state_management_node(state: ConversationState):
            """çŠ¶æ…‹ç®¡ç†ãƒãƒ¼ãƒ‰"""
            if state["should_continue_processing"]:
                self.conversation_manager.save_continuation_state(state)
            
            return {"cycle_complete": True}
        
        def should_continue_conversation(state: ConversationState):
            """ä¼šè©±ã‚µã‚¤ã‚¯ãƒ«ã‚’ç¶šã‘ã‚‹ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
            if state.get("cycle_complete", False):
                return END
            return "response_preparation"
        
        # ConversationStateç”¨ã®ã‚°ãƒ©ãƒ•ï¼ˆä¼šè©±ã‚µã‚¤ã‚¯ãƒ«ï¼‰
        conversation_workflow = StateGraph(ConversationState)
        conversation_workflow.add_node("input_analysis", input_analysis_node)
        conversation_workflow.add_node("agent_processing", agent_processing_node)
        conversation_workflow.add_node("response_preparation", response_preparation_node)
        conversation_workflow.add_node("state_management", state_management_node)
        conversation_workflow.add_edge(START, "input_analysis")
        conversation_workflow.add_edge("input_analysis", "agent_processing")
        conversation_workflow.add_edge("agent_processing", "response_preparation")
        conversation_workflow.add_edge("response_preparation", "state_management")
        conversation_workflow.add_conditional_edges("state_management", should_continue_conversation, ["response_preparation", END])
        
        return conversation_workflow.compile()
    
    async def _resume_processing(self, state: ConversationState):
        """ç¶™ç¶šå‡¦ç†ã‚’å®Ÿè¡Œ"""
        session_id = state["session_id"]
        
        saved_state = self.conversation_manager.get_continuation_state(session_id)
        if saved_state:
            # ä¿å­˜ã•ã‚ŒãŸçµæœã‚’è¿”ã™ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯å‡¦ç†ã‚’å†é–‹ï¼‰
            return {
                "current_task": saved_state["current_task"],
                "partial_result": saved_state["partial_result"],
                "is_processing": False,
                "has_timeout": False
            }
        else:
            return {
                "current_task": "ç¶™ç¶šå‡¦ç†",
                "partial_result": "ç¶™ç¶šã™ã‚‹å‡¦ç†ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ",
                "is_processing": False,
                "has_timeout": False
            }
    
    async def _process_with_timeout_monitoring(self, state: ConversationState):
        """ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç›£è¦–ä»˜ãå‡¦ç†"""
        TIMEOUT_SECONDS = 7.0  # å®‰å…¨ãƒãƒ¼ã‚¸ãƒ³
        processing_start = state["processing_start_time"]
        
        # AgentStateã‚’æ§‹ç¯‰
        agent_state = AgentState(
            messages=state["messages"],
            device_ids=state["device_ids"],
            llm_provider=state["llm_provider"]
        )
        
        try:
            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚°ãƒ©ãƒ•ã‚’ä½œæˆï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
            agent_graph = self.create_agent_graph()
            
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãã§ã‚°ãƒ©ãƒ•å®Ÿè¡Œ
            result = await asyncio.wait_for(
                agent_graph.ainvoke(agent_state),
                timeout=TIMEOUT_SECONDS
            )
            
            # æˆåŠŸæ™‚ã®å‡¦ç†
            final_response = self._extract_agent_response(result)
            return {
                "current_task": "å‡¦ç†å®Œäº†",
                "partial_result": final_response,
                "is_processing": False,
                "has_timeout": False
            }
            
        except asyncio.TimeoutError:
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚ã®å‡¦ç†
            elapsed = time.time() - processing_start
            return {
                "current_task": "æƒ…å ±ã‚’å–å¾—ä¸­",
                "partial_result": f"å‡¦ç†ä¸­ã§ã™ï¼ˆ{elapsed:.1f}ç§’çµŒéï¼‰",
                "is_processing": True,
                "has_timeout": True
            }
    
    def _extract_agent_response(self, result):
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œçµæœã‹ã‚‰å¿œç­”ã‚’æŠ½å‡º"""
        if "messages" in result and result["messages"]:
            last_message = result["messages"][-1]
            if isinstance(last_message, AIMessage):
                return last_message.content
        return "å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚"